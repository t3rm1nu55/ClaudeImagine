# Claude CLI Comprehensive Testing Summary

## ‚úÖ Successfully Tested & Working

### 1. Model Selection ‚úÖ
- **Sonnet**: Default, cost-effective ($0.01 for simple queries)
- **Opus**: Higher quality, ~3x more expensive ($0.03 for same query)
- **Haiku**: Fastest, cheapest (used for some internal operations)
- Selection via `--model` flag works perfectly

### 2. Token Usage & Cost Tracking ‚úÖ
**Full visibility into:**
- Input/output token counts
- Total cost per request (USD)
- Per-model breakdown (Haiku/Sonnet/Opus)
- Cache usage (creation/read tokens)
- Response duration (ms)
- Session IDs and request UUIDs

**Example JSON output:**
```json
{
  "usage": {
    "input_tokens": 2,
    "output_tokens": 68,
    "cache_creation_input_tokens": 17510,
    "cache_read_input_tokens": 0
  },
  "total_cost_usd": 0.012709999999999999,
  "duration_ms": 3182,
  "modelUsage": {
    "claude-sonnet-4-5-20250929": {
      "inputTokens": 610,
      "outputTokens": 201,
      "costUSD": 0.011342999999999999
    }
  }
}
```

### 3. Streaming Output ‚úÖ
- Real-time streaming with `--output-format stream-json`
- Requires `--verbose --include-partial-messages`
- Multiple chunks per response
- Event types: `system`, `stream_event`, `message_start`, `content_block_delta`, etc.

### 4. Output Formats ‚úÖ
- `text` (default) - Plain text
- `json` - Single JSON with full metadata
- `stream-json` - Real-time streaming (requires `--verbose`)

### 5. Debug Mode ‚úÖ
- `--debug [filter]` for detailed logging
- Categories: `api`, `hooks`, `statsig`, `file`
- Can filter: `"api,hooks"` or `"!statsig,!file"`

### 6. MCP Server Registration ‚úÖ
- Server successfully registered: `imagine: ‚úì Connected`
- Tools visible: `mcp__imagine__update_ui`, `mcp__imagine__log_thought`
- MCP commands work: `claude mcp list`, `claude mcp get imagine`

## ‚ö†Ô∏è Partially Working / Needs Investigation

### 1. MCP Tool Execution ‚ö†Ô∏è

**Status:** Tools are visible but execution is inconsistent

**Findings:**
- ‚úÖ Tools appear in tool list: `mcp__imagine__update_ui`, `mcp__imagine__log_thought`
- ‚ö†Ô∏è Sometimes Claude says tools are "not available"
- ‚ö†Ô∏è Sometimes requires "permission" to use tools
- ‚ö†Ô∏è Server must be running before Claude starts

**Possible Issues:**
1. **Timing**: Server needs to be running and ready before Claude queries tools
2. **Permissions**: May need explicit permission granting for MCP tools
3. **Connection**: stdio connection may be intermittent
4. **Session**: Each `--print` call may create new MCP connection

**Workaround:**
- Start server first: `node server-mcp.js &`
- Wait 2-3 seconds
- Then run Claude CLI
- May need interactive mode instead of `--print`

### 2. State Management ‚ö†Ô∏è

**Status:** `--print` mode doesn't maintain state

**Behavior:**
- Each `claude --print` call is independent
- No conversation history between calls
- Cannot test "remembering" across calls

**Solution:**
- Use interactive mode (`claude` without `--print`) for state
- Or use `--continue` / `--resume` flags for session management

## ‚ùå Not Tested / Unknown

### 1. Thinking Mode
- Not tested - may require interactive mode
- May be model-specific (Opus?)
- May need special configuration

### 2. Multimodality
- Image inputs not tested
- File attachments not tested
- Mixed content types not tested

### 3. Tool Budgets/Limits
- No explicit budget limits found in output
- Token limits may be account-based
- Rate limiting not visible in output

## üìä Cost Analysis

### Token Costs (from tests):

**Simple Query (2+2):**
- Sonnet: $0.01 (2 input, 4 output tokens)
- Opus: $0.03 (2 input, 4 output tokens)
- **Opus is 3x more expensive**

**Complex Query (50 words about AI):**
- Sonnet: $0.0127 (2 input, 68 output tokens)
- Duration: 3182ms

### Cache Impact:
- `cache_creation_input_tokens`: 17,510 (one-time cost)
- `cache_read_input_tokens`: 0 (no cache hits yet)
- **Cache can significantly reduce costs** for repeated queries

### Cost Optimization Tips:
1. Use **Sonnet** for most tasks (cost-effective)
2. Use **Opus** only for complex reasoning
3. Enable **caching** when possible
4. Monitor `total_cost_usd` to track spending
5. Check `input_tokens` vs `output_tokens` ratio

## üîç Telemetry & Monitoring

### Available Metrics:
‚úÖ Token counts (input/output/cache)
‚úÖ Cost tracking (per request, per model)
‚úÖ Duration (API response time)
‚úÖ Cache hit rates
‚úÖ Session IDs
‚úÖ Request UUIDs
‚úÖ Model usage breakdown

### Debug Information:
‚úÖ API calls and responses
‚úÖ MCP server connections
‚úÖ Tool execution attempts
‚úÖ Error details

## üöÄ Best Practices

### 1. Model Selection:
```bash
# Cost-effective (default)
claude --print --model sonnet "prompt"

# Highest quality (3x cost)
claude --print --model opus "prompt"

# Fastest, cheapest
claude --print --model haiku "prompt"
```

### 2. Token Tracking:
```bash
# Get detailed token usage
claude --print --model sonnet --output-format json "prompt"

# Monitor costs
# Check: total_cost_usd, usage.input_tokens, usage.output_tokens
```

### 3. Streaming:
```bash
# Real-time streaming
claude --print --model sonnet \
  --output-format stream-json \
  --verbose \
  --include-partial-messages \
  "prompt"
```

### 4. MCP Tools:
```bash
# List MCP servers
claude mcp list

# Get server details
claude mcp get imagine

# Use MCP tools (when available)
# Tools prefixed with: mcp__imagine__
```

### 5. Debugging:
```bash
# API-level debugging
claude --print --model sonnet --debug api "prompt"

# Multiple categories
claude --print --model sonnet --debug "api,hooks" "prompt"
```

## üîß Known Limitations

### 1. `--print` Mode:
- ‚ùå No state management (each call is independent)
- ‚ùå May not maintain MCP connections between calls
- ‚úÖ Good for one-off queries and scripts

### 2. MCP Tool Execution:
- ‚ö†Ô∏è Requires server to be running first
- ‚ö†Ô∏è May need permission granting
- ‚ö†Ô∏è Connection may be intermittent
- ‚úÖ Tools are discoverable when server is connected

### 3. Streaming:
- ‚ö†Ô∏è Requires `--verbose` flag
- ‚ö†Ô∏è Only works with `stream-json` format
- ‚úÖ Works well for long responses

## üìù Command Reference

### Basic Usage:
```bash
# Simple query
claude --print --model sonnet "prompt"

# JSON output with tokens
claude --print --model sonnet --output-format json "prompt"

# Streaming
claude --print --model sonnet --output-format stream-json --verbose --include-partial-messages "prompt"
```

### MCP Configuration:
```bash
# List MCP servers
claude mcp list

# Add MCP server
claude mcp add-json name '{"command":"node","args":["script.js"]}'

# Get server details
claude mcp get name

# Remove server
claude mcp remove name
```

### Debug & Monitoring:
```bash
# Debug mode
claude --print --model sonnet --debug api "prompt"

# Verbose output
claude --print --model sonnet --verbose "prompt"
```

## üéØ Key Takeaways

1. ‚úÖ **Token tracking is excellent** - Full visibility into costs and usage
2. ‚úÖ **Model selection works** - Can choose Sonnet/Opus/Haiku based on needs
3. ‚úÖ **Streaming works** - Real-time updates available
4. ‚úÖ **MCP tools are discoverable** - Tools appear when server is connected
5. ‚ö†Ô∏è **MCP execution needs work** - Timing/permission issues
6. ‚ùå **State management** - Requires interactive mode, not `--print`
7. ‚úÖ **Cost tracking** - Excellent visibility into spending
8. ‚úÖ **Cache usage** - Significant cost savings possible

## üîÆ Next Steps

1. **Fix MCP Tool Execution:**
   - Test with interactive mode (not `--print`)
   - Ensure server starts before Claude
   - Check permission system
   - Test tool execution end-to-end

2. **Test State Management:**
   - Use interactive mode
   - Test conversation continuity
   - Test memory across turns
   - Use `--continue` / `--resume` flags

3. **Test Thinking Mode:**
   - Check if available in interactive mode
   - Test with different models
   - Compare thinking vs non-thinking

4. **Test Multimodality:**
   - Image inputs
   - File attachments
   - Mixed content types

5. **Test Tool Budgets:**
   - Check for rate limits
   - Test tool call limits
   - Monitor token budgets

## üìà Performance Metrics

### Response Times:
- Simple queries: ~3 seconds
- Complex queries: ~3-5 seconds
- Streaming: Real-time (chunks arrive as generated)

### Token Efficiency:
- Cache can reduce costs significantly
- Input tokens typically small (2-10 for prompts)
- Output tokens vary by response length
- Cache creation is one-time cost

### Cost Efficiency:
- Sonnet: Best balance
- Opus: Highest quality, 3x cost
- Haiku: Fastest, cheapest (internal use)

